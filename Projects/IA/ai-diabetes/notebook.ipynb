{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9623f3f",
   "metadata": {},
   "source": [
    "# Diabetes prediction\n",
    "Supervised Learning\n",
    "\n",
    "> Faculty of Engineering at University of Porto  \n",
    "> Bachelor's Degree in Informatics and Computing Engineering  \n",
    "> Artificial Intelligence (L.EIC029) 2024/2025\n",
    ">\n",
    "> - Luís Paulo Gonçalves dos Reis (Regent of the course)\n",
    "> - Telmo João Vales Ferreira Barros (Theoretical-Practical classes)\n",
    "\n",
    "> **Class 09; Group 02**\n",
    ">\n",
    "> - Duarte Souto Assunção (up202208319@up.pt)\n",
    "> - Guilherme Duarte Silva Matos (up202208755@up.pt)\n",
    "> - João Vítor da Costa Ferreira (up202208393@up.pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477b9dce",
   "metadata": {},
   "source": [
    "Before running this notebook, read the [README.md](./README.md) with the software prerequisites and installation process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f1d9b7",
   "metadata": {},
   "source": [
    "## Problem definition and data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f026a1d5",
   "metadata": {},
   "source": [
    "This is a binary classification problem, where the objective is to **predict the diabetes status of the patient**, given various biomedical measurements and patient characteristics.\n",
    "\n",
    "The [given dataset](./dataset.csv) has these characteristics:\n",
    "- 800 unique patients;\n",
    "- 200 duplicate IDs with different genders (assumed to be different patients);\n",
    "- 56% male and 43% female;\n",
    "- 70.6% of patients are between 50 and 61 years old;\n",
    "- Urea, Cr, TG, HDL and VLDL may have outliers;\n",
    "- 84% of patients have diabetes, i.e., the database is highly unbalanced!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cccfaa",
   "metadata": {},
   "source": [
    "## 0. Crate imports and initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32fe81d",
   "metadata": {},
   "source": [
    "⚠️ Make sure to execute this **before everything**!\n",
    "\n",
    "⚠️ This step may take ~5 minutes for the first time!\n",
    "\n",
    "- This code snippet compiles all dependencies and auxiliary modules;\n",
    "\n",
    "- The compilation process is reused between runs in the same kernel instance;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40851a8a",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [],
   "source": [
    "// Auxiliary library at ./src (if needed)\n",
    ":dep ai_lib = { package = \"ai-diabetes\", path = \".\", version = \"*\" }\n",
    "\n",
    ":dep csv = { version = \"1.3.1\" }\n",
    ":dep rand = { version = \"0.8.5\" }\n",
    "\n",
    "// ~ Scikit-learn\n",
    ":dep linfa = { version = \"0.7.1\" }\n",
    ":dep linfa-svm = { version = \"0.7.2\" }\n",
    ":dep linfa-trees = { version = \"0.7.1\" }\n",
    ":dep linfa-bayes = { version = \"0.7.1\" }\n",
    ":dep linfa-preprocessing = { version = \"0.7.1\" }\n",
    "\n",
    "// ~ NumPy\n",
    ":dep ndarray = { version = \"0.15\", default-features = false } \n",
    ":dep ndarray-csv = { version = \"0.5.1\" }\n",
    "\n",
    "// ~ Matplotlib\n",
    ":dep plotters = { version = \"0.3.7\", features = [\"boxplot\", \"evcxr\", \"all_series\", \"all_elements\"] } \n",
    "\n",
    "// ~ Pandas\n",
    ":dep polars = { version = \"0.46.0\", features = [\"lazy\", \"csv\", \"polars-io\", \"describe\"] }  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b078be4",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Type Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739ddbd4",
   "metadata": {},
   "source": [
    "Loading the [dataset.csv](./dataset.csv) into:\n",
    "- A two-dimentional array with the features (`data`);\n",
    "- An array with the targets, i.e., the \"Class\" column (`targets`).\n",
    "\n",
    "To assure the same type (`f64`) for all the data, in this step some data preprocessing is done:\n",
    "- The first two columns (\"ID\" and \"No_Pation\") are not included in `data`;\n",
    "- Columns \"Gender\" and \"Class\" are converted into a boolean (and casted into f64)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ca66b4c",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use csv::ReaderBuilder;\n",
    "use ndarray::Array1;\n",
    "use ndarray::Array2;\n",
    "use std::num::ParseFloatError;\n",
    "use ndarray::Axis;\n",
    "use ndarray::ArrayView;\n",
    "\n",
    "const CSV_PATH: &str = \"dataset.csv\";\n",
    "let columns: Vec<&'static str> = vec![\n",
    "    \"Gender\", \"AGE\", \"Urea\", \"Cr\", \"HbA1c\", \"Chol\", \"TG\", \"HDL\", \"LDL\", \"VLDL\", \"BMI\",\n",
    "];\n",
    "\n",
    "let mut reader = ReaderBuilder::new()\n",
    "    .has_headers(true)\n",
    "    .delimiter(b',')\n",
    "    .from_path(CSV_PATH)\n",
    "    .expect(\"Cannot create reader\");\n",
    "\n",
    "let mut data: Array2<f64> = Array2::zeros((0, 11));\n",
    "let mut targets: Array1<bool> = Array1::default(0);\n",
    "for result in reader.records() {\n",
    "    let record = result.expect(\"Error reading record\");\n",
    "    let row: Vec<String> = record.iter().map(|s| s.to_string()).collect();\n",
    "\n",
    "    // The first two columns (Id, No_Pation) are not used in the model\n",
    "    let mut filtered_row = row[2..].to_vec();\n",
    "\n",
    "    // Convert \"Gender\" to \"bool\" casted as f64\n",
    "    match filtered_row[0].as_str().trim() {\n",
    "        \"M\" | \"m\" => filtered_row[0] = \"1\".to_string(),\n",
    "        \"F\" | \"f\" => filtered_row[0] = \"0\".to_string(),\n",
    "        _ => {}\n",
    "    }\n",
    "\n",
    "    // Convert \"Class\" to \"bool\" casted as f64\n",
    "    match filtered_row[11].as_str().trim() {\n",
    "        \"N\" | \"n\" => filtered_row[11] = \"0\".to_string(),\n",
    "        \"P\" | \"p\" => filtered_row[11] = \"0\".to_string(),\n",
    "        \"Y\" | \"y\" => filtered_row[11] = \"1\".to_string(),\n",
    "        _ => {}\n",
    "    }\n",
    "\n",
    "    let parsed_row = filtered_row\n",
    "        .iter()\n",
    "        .map(|s| s.trim().parse::<f64>())\n",
    "        .collect::<Result<Vec<f64>, ParseFloatError>>()\n",
    "        .expect(\"Error parsing row\");\n",
    "\n",
    "    let _ = data.append(\n",
    "        Axis(0),\n",
    "        ArrayView::from_shape((1, 11), &parsed_row[0..11]).unwrap(),\n",
    "    );\n",
    "    let _ = targets.append(\n",
    "        Axis(0),\n",
    "        ArrayView::from_shape(1, &[((parsed_row[11] - 1.0).abs() <= f64::EPSILON)])\n",
    "            .unwrap(),\n",
    "    );\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba934ad4",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350cccaf",
   "metadata": {},
   "source": [
    "No data cleaning is needed due to the nature of this dataset:\n",
    "- Despite all columns having outliers, these values are still valid and accurate;\n",
    "- No `null` or missing values are present;\n",
    "- There are 200 duplicate patient IDs, but the values are different and captured\n",
    "after many years, so no duplicate patient will be removed and therefore, treated\n",
    "as a new patient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2b2c3c",
   "metadata": {},
   "source": [
    "Remember that the columns \"ID\" and \"No_Pation\" were already removed and that \n",
    "this dataset is small with only 1000 entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ec9fb2",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c451bbb",
   "metadata": {},
   "source": [
    "### 3.1. Oversample non-diabetic classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83449183",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use ndarray::s;\n",
    "\n",
    "let mut non_diabetic_indices = Vec::new();\n",
    "for (i, &target) in targets.iter().enumerate() {\n",
    "    if !target {\n",
    "        non_diabetic_indices.push(i);\n",
    "    }\n",
    "}\n",
    "\n",
    "let diabetic_count = targets.iter().filter(|&&t| t).count();\n",
    "let non_diabetic_count = non_diabetic_indices.len();\n",
    "let oversample_count = diabetic_count - non_diabetic_count;\n",
    "\n",
    "for _ in 0..oversample_count {\n",
    "    let random_index = non_diabetic_indices[rand::random::<usize>() % non_diabetic_count];\n",
    "    let new_row = data.slice(s![random_index, ..]).to_owned().to_vec();\n",
    "    let new_target = targets[random_index];\n",
    "    data.append(Axis(0), ArrayView::from_shape((1, 11), &new_row).unwrap())\n",
    "        .expect(\"Error appending oversampled row\");\n",
    "    targets.append(\n",
    "        Axis(0),\n",
    "        ArrayView::from_shape(1, &[new_target]).unwrap(),\n",
    "    ).expect(\"Error appending oversampled target\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3173ff89",
   "metadata": {},
   "source": [
    "### 3.2. Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d084bb43",
   "metadata": {},
   "source": [
    "In this specific dataset, normalization of the features via l1, l2 or max norms \n",
    "results in worse models, especially for SVM, so, normalization is avoided in this\n",
    "pipeline.\n",
    "\n",
    "⚠️ The code is commented out! To run this step, remove the characters `/*` and `*/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "58e4b8c8",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [],
   "source": [
    "use linfa_preprocessing::norm_scaling::NormScaler;\n",
    "\n",
    "/* // <- Remove here the comment to use L1 normalization\n",
    "let temp_dataset = Dataset::new(data.clone(), targets.clone()).with_feature_names(columns.clone());\n",
    "let scaler = NormScaler::l1();\n",
    "let temp_dataset = scaler.transform(temp_dataset);\n",
    "let data = temp_dataset.records().to_owned();\n",
    "let targets = temp_dataset.targets().to_owned();\n",
    "*/ // <-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822a6e6c",
   "metadata": {},
   "source": [
    "### 3.3. New features for highly correlated columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d11a79a",
   "metadata": {},
   "source": [
    "No pair of features has a high enough correlation to be merged into one column.\n",
    "No action is needed.\n",
    "\n",
    "See the correlation heatmap below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d293ceaa",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender0.06 0.13 0.17 0.05 -0.05 0.14 -0.16 0.02 0.18 0.06 \n",
      "AGE                0.11 0.07 0.46 -0.00 0.16 -0.02 -0.02 -0.02 0.47 \n",
      "Urea                            0.65 0.04 -0.01 0.09 -0.00 -0.01 -0.00 0.07 \n",
      "Cr                                           -0.00 -0.04 0.10 -0.01 0.05 0.02 0.04 \n",
      "HbA1c                                                     0.23 0.26 0.02 -0.01 0.13 0.62 \n",
      "Chol                                                                   0.27 0.09 0.42 0.09 0.12 \n",
      "TG                                                                                  -0.11 0.03 0.17 0.19 \n",
      "HDL                                                                                              -0.14 -0.06 0.05 \n",
      "LDL                                                                                                           0.05 -0.03 \n",
      "VLDL                                                                                                                       0.23 \n",
      "BMI\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Print a correlation heatmap\n",
    "use linfa::Dataset;\n",
    "\n",
    "let temp_dataset = Dataset::new(data.clone(), targets.clone()).with_feature_names(columns.clone());\n",
    "let correlation = temp_dataset.pearson_correlation();\n",
    "println!(\"{}\", correlation);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0781a604",
   "metadata": {},
   "source": [
    "## 4. Model Creation and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "67170932",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [],
   "source": [
    "use ai_lib::Aux;\n",
    "use ai_lib::ModelKind;\n",
    "use linfa::prelude::*;\n",
    "\n",
    "let dataset = Dataset::new(data.clone(), targets.clone()).with_feature_names(columns.clone());\n",
    "let dataset = dataset.shuffle(&mut rand::thread_rng());\n",
    "let (train_data, test_data) = dataset.split_with_ratio(0.8);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a949b32",
   "metadata": {},
   "source": [
    "### 4.1. Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4af68ebf",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      "Training took 377.84 ms;\n",
      "Testing took 4.25 ms;\n",
      "Accuracy of 97.92 %;\n",
      "Sensitivity of 95.86 %\n",
      "Precision of 100.00 %\n",
      "F1 scores of 0.98\n",
      "Confusion Matrix: \n",
      "\n",
      "classes    | false      | true      \n",
      "false      | 162        | 7         \n",
      "true       | 0          | 168       \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "let svm = Aux::train_and_test(ModelKind::SVM, &train_data, &test_data);\n",
    "println!(\"{}\", svm);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40825355",
   "metadata": {},
   "source": [
    "### 4.2. Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c1f54ed",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB:\n",
      "Training took 0.60 ms;\n",
      "Testing took 0.11 ms;\n",
      "Accuracy of 91.10 %;\n",
      "Sensitivity of 93.41 %\n",
      "Precision of 89.14 %\n",
      "F1 scores of 0.91\n",
      "Confusion Matrix: \n",
      "\n",
      "classes    | true       | false     \n",
      "true       | 156        | 11        \n",
      "false      | 19         | 151       \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "let gnb = Aux::train_and_test(ModelKind::GNB, &train_data, &test_data);\n",
    "println!(\"{}\", gnb);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7f7ef1",
   "metadata": {},
   "source": [
    "### 4.3. (Linear) Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0dd83656",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDT:\n",
      "Training took 5.75 ms;\n",
      "Testing took 0.02 ms;\n",
      "Accuracy of 97.33 %;\n",
      "Sensitivity of 98.26 %\n",
      "Precision of 96.57 %\n",
      "F1 scores of 0.97\n",
      "Confusion Matrix: \n",
      "\n",
      "classes    | true       | false     \n",
      "true       | 169        | 3         \n",
      "false      | 6          | 159       \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "let ldt = Aux::train_and_test(ModelKind::LDT, &train_data, &test_data);\n",
    "println!(\"{}\", ldt);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea145387",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[License](LICENSE) | [Third Party Credits](THIRDPARTY.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "Rust",
   "pygment_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
